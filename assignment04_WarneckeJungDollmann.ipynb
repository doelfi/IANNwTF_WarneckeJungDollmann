{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-82cde96efcb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import datetime\n",
    "%load_ext tensorboard\n",
    "(train_ds, test_ds), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) a + b >= 5 </br>\n",
    "single binary output\n",
    "\n",
    "2) y = a - b </br>\n",
    "integer in range [-9,9]\n",
    "One-hots with 18 values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the data pipeline for subtask one (a + b >= 5)\n",
    "\n",
    "def prepare_subtask_1(mnist):\n",
    "    # flatten the images into vectors\n",
    "    mnist = mnist.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "    # convert data from uint8 to float32\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # bringing image values from range [0,255] to [-1,1]\n",
    "    mnist = mnist.map(lambda img, target: ((img/128.)-1., target))\n",
    "    # zip two random parts of the dataset result will be a tuple of tuples: ((i1,t1),(i2,t2))\n",
    "    mnist = tf.data.Dataset.zip((mnist.shuffle(2000),mnist.shuffle(2000)))\n",
    "    # flatten the nested tuples into shape: (i1,i2,t) and calculate the new target\n",
    "    mnist = mnist.map(lambda d1, d2: (d1[0],d2[0],d1[1] + d2[1] >= 5))\n",
    "    # cache progress in memory\n",
    "    mnist = mnist.cache()\n",
    "    # shuffle, batch, prefetch\n",
    "    mnist = mnist.shuffle(1000)\n",
    "    mnist = mnist.batch(32)\n",
    "    mnist = mnist.prefetch(20)\n",
    "    \n",
    "    # return processed dataset\n",
    "    return mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the data pipeline for subtask 2 (y = a - b)\n",
    "\n",
    "def prepare_subtask_2(mnist):\n",
    "    # flatten the images into vectors\n",
    "    mnist = mnist.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "    # convert data from uint8 to float32\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # bringing image values from range [0,255] to [-1,1]\n",
    "    mnist = mnist.map(lambda img, target: ((img/128.)-1., target))\n",
    "    # zip two random parts of the dataset result will be a tuple of tuples: ((i1,t1),(i2,t2))\n",
    "    mnist = tf.data.Dataset.zip((mnist.shuffle(2000),mnist.shuffle(2000)))\n",
    "    # flatten the nested tuples into shape: (i1,i2,t) and calculate new target\n",
    "    mnist = mnist.map(lambda d1, d2: (d1[0],d2[0],d1[1] - d2[1]))\n",
    "    # create one-hot targets with depth 19 to accomodate all values between -9 and 9\n",
    "    # since 0 - 9 and 9 - 0 are the smallest and biggest possible target\n",
    "    mnist = mnist.map(lambda img1, img2, target: (img1, img2, tf.one_hot(target, depth=19)))\n",
    "    # cache progress in memory\n",
    "    mnist = mnist.cache()\n",
    "    # shuffle, batch, prefetch\n",
    "    mnist = mnist.shuffle(1000)\n",
    "    mnist = mnist.batch(32)\n",
    "    mnist = mnist.prefetch(20)\n",
    "    # return processed dataset\n",
    "    return mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for Subtask 1 (a + b >= 5)\n",
    "class ModelOne(tf.keras.Model):\n",
    "    def __init__(self, optimizer):\n",
    "        super().__init__()\n",
    "        \n",
    "        # optimizer as passable parameter so we can run different tests with SGD and Adam\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # some metrics\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.Mean(name=\"loss\"),\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"acc\")    \n",
    "        ]\n",
    "        \n",
    "        # binary loss function as output can either be 0 or 1\n",
    "        self.loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "        \n",
    "        # define layers\n",
    "        # layer 1 to 3 are bascially the same network architecture as last week to decode the number\n",
    "        # layer 4 will do the combination of both\n",
    "        # output will be a single probability \n",
    "        self.layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.layer2 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.layer3 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        self.layer4 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.output_unit = tf.keras.layers.Dense(1, activation=tf.nn.softmax)\n",
    "    \n",
    "    # reuse the first layers for both inputs\n",
    "    def call(self, x, training=False):\n",
    "        img1, img2 = x\n",
    "        # get activation for the first digit\n",
    "        digit1 = self.layer1(img1)\n",
    "        digit1 = self.layer2(digit1)\n",
    "        digit1 = self.layer3(digit1)\n",
    "        \n",
    "        # get activation for the second digit\n",
    "        digit2 = self.layer1(img2)\n",
    "        digit2 = self.layer2(digit2)\n",
    "        digit2 = self.layer3(digit2)\n",
    "        \n",
    "        # add outputs together\n",
    "        #joined = digit1 + digit2\n",
    "        joined = tf.concat([digit1, digit2], axis = 1)\n",
    "        \n",
    "        # get activation for the combination\n",
    "        out = self.layer4(joined)\n",
    "        out = self.output_unit(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # reset all collected metrics\n",
    "    def reset_metrics(self):\n",
    "        \n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "            \n",
    "    \n",
    "    # define train step\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        # I have a triple instead of tuple, so I have to split it into three parts\n",
    "        x1, x2, targets = data\n",
    "        # and add the first two to a seperate tuple again, to feed it into the network\n",
    "        x = (x1,x2)\n",
    "        \n",
    "        # get gradients and apply them to the optimizer\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(x, training=True)\n",
    "            loss = self.loss_function(targets,predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "        \n",
    "        # for all metrics except loss, update states (in this case only accuracy)\n",
    "        self.metrics[1].update_state(targets,predictions)\n",
    "            \n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        # prepare data in the same way as above\n",
    "        x1, x2, targets = data\n",
    "        x = (x1,x2)\n",
    "        predictions = self(x, training=False)\n",
    "        loss = self.loss_function(targets, predictions)\n",
    "        \n",
    "        # update metrics\n",
    "        self.metrics[0].update_state(loss)\n",
    "        self.metrics[1].update_state(targets, predictions)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for Subtask 1 (a + b >= 5)\n",
    "class ModelTwo(tf.keras.Model):\n",
    "    def __init__(self, optimizer):\n",
    "        super().__init__()\n",
    "        \n",
    "        # optimizer as passable parameter so we can run different tests with SGD and Adam\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # some metrics\n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.Mean(name=\"loss\"),\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"acc\")    \n",
    "        ]\n",
    "        \n",
    "        # categorical loss function as we have one-hots again\n",
    "        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "        \n",
    "        # define layers\n",
    "        # layer 1 to 3 are bascially the same network architecture as last week to decode the number\n",
    "        # layer 4 will do the combination of both\n",
    "        self.layer1 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.layer2 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.layer3 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        self.layer4 = tf.keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.output_unit = tf.keras.layers.Dense(19, activation=tf.nn.softmax)\n",
    "    \n",
    "    # reuse the first layers for both inputs\n",
    "    def call(self, x, training=False):\n",
    "        img1, img2 = x\n",
    "        # get activation for the first digit\n",
    "        digit1 = self.layer1(img1)\n",
    "        digit1 = self.layer2(digit1)\n",
    "        digit1 = self.layer3(digit1)\n",
    "        \n",
    "        # get activation for the second digit\n",
    "        digit2 = self.layer1(img2)\n",
    "        digit2 = self.layer2(digit2)\n",
    "        digit2 = self.layer3(digit2)\n",
    "        \n",
    "        # add outputs together\n",
    "        #joined = digit1 + digit2\n",
    "        joined = tf.concat([digit1, digit2], axis = 1)\n",
    "        \n",
    "        # get activation for the combination\n",
    "        out = self.layer4(joined)\n",
    "        out = self.output_unit(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # reset all collected metrics\n",
    "    def reset_metrics(self):\n",
    "        \n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "            \n",
    "    \n",
    "    # define train step\n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        # I have a triple instead of tuple, so I have to split it into three parts\n",
    "        x1, x2, targets = data\n",
    "        # and add the first two to a seperate tuple again, to feed it into the network\n",
    "        x = (x1,x2)\n",
    "        \n",
    "        # get gradients and apply them to the optimizer\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(x, training=True)\n",
    "            loss = self.loss_function(targets,predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        # update loss metric\n",
    "        self.metrics[0].update_state(loss)\n",
    "        \n",
    "        # for all metrics except loss, update states (in this case only accuracy)\n",
    "        self.metrics[1].update_state(targets,predictions)\n",
    "            \n",
    "        # Return a dictionary mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        # prepare data in the same way as above\n",
    "        x1, x2, targets = data\n",
    "        x = (x1,x2)\n",
    "        predictions = self(x, training=False)\n",
    "        loss = self.loss_function(targets, predictions)\n",
    "        \n",
    "        # update metrics\n",
    "        self.metrics[0].update_state(loss)\n",
    "        self.metrics[1].update_state(targets, predictions)\n",
    "            \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import tqdm\n",
    "\n",
    "def training_loop(model, train_ds, val_ds, epochs, train_summary_writer, val_summary_writer):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        \n",
    "        # Training:\n",
    "        \n",
    "        for data in tqdm.tqdm(train_ds, position=0, leave=True):\n",
    "            metrics = model.train_step(data)\n",
    "            \n",
    "            # logging the validation metrics to the log file which is used by tensorboard\n",
    "            with train_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "\n",
    "        # print the metrics\n",
    "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # reset all metrics (requires a reset_metrics method in the model)\n",
    "        model.reset_metrics()    \n",
    "        \n",
    "        # Validation:\n",
    "        for data in val_ds:\n",
    "            metrics = model.test_step(data)\n",
    "        \n",
    "            # logging the validation metrics to the log file which is used by tensorboard\n",
    "            with val_summary_writer.as_default():\n",
    "                for metric in model.metrics:\n",
    "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
    "                    \n",
    "        print([f\"val_{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
    "\n",
    "        # reset all metrics\n",
    "        model.reset_metrics()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8cdd490be8110978\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8cdd490be8110978\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete training with instanciating everything necessary beforhand\n",
    "# subtask is indicated by a number (1 or 2)\n",
    "def automated_training(subtask,optimizer,epochs):\n",
    "    if subtask == 1:\n",
    "        model = ModelOne(optimizer)\n",
    "        train_data = train_ds.apply(prepare_subtask_1)\n",
    "        test_data = test_ds.apply(prepare_subtask_1)\n",
    "    elif subtask == 2:\n",
    "        model = ModelTwo(optimizer)\n",
    "        train_data = train_ds.apply(prepare_subtask_2)\n",
    "        test_data = test_ds.apply(prepare_subtask_2)\n",
    "    else:\n",
    "        print(\"Not a valid input.\")\n",
    "        return\n",
    "    \n",
    "    # get a handle for the optimizer to print to the log\n",
    "    # I know this is not the nicest way to do this...\n",
    "    if optimizer == type(tf.keras.optimizers.SGD()):\n",
    "        name = \"SGD\"\n",
    "    elif optimizer == type(tf.keras.optimizers.Adam()):\n",
    "        name = \"Adam\"\n",
    "    else:\n",
    "        name = \"other\"\n",
    "    \n",
    "    # Define where to save the log\n",
    "    config_name= \"config_name\"\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    train_log_path = f\"logs/{config_name}/{current_time}/train/task{str(subtask)}/{name}\"\n",
    "    val_log_path = f\"logs/{config_name}/{current_time}/val/task{str(subtask)}/{name}\"\n",
    "\n",
    "    # log writer for training metrics\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_path)\n",
    "\n",
    "    # log writer for validation metrics\n",
    "    val_summary_writer = tf.summary.create_file_writer(val_log_path)\n",
    "    \n",
    "    # run the training loop \n",
    "    training_loop(model=model, \n",
    "            train_ds=train_data, \n",
    "            val_ds=test_data, \n",
    "            epochs=epochs, \n",
    "            train_summary_writer=train_summary_writer, \n",
    "            val_summary_writer=val_summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = tf.keras.optimizers.SGD()\n",
    "type(op) == type(tf.keras.optimizers.SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc81f6c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc81f6c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc81f6c10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:03<00:00, 531.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406857967376709', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5044918060302734', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 685.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.40685772895813', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5060153007507324', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 677.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4068593978881836', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5044913291931152', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 685.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406857967376709', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.504490375518799', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 677.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4068596363067627', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.506014108657837', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 679.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406855583190918', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5075366497039795', 'val_acc: 0.8355631232261658']\n",
      "\n",
      "\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 685.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406857967376709', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5060136318206787', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:03<00:00, 531.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406857967376709', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.506014108657837', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 686.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4068586826324463', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.5060153007507324', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 691.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.406858444213867', 'acc: 0.8421666622161865']\n",
      "['val_loss: 2.50296950340271', 'val_acc: 0.8358626365661621']\n",
      "\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc8146d30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc815a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc815a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc815a040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:03<00:00, 528.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.433544158935547', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.5075368881225586', 'val_acc: 0.8355631232261658']\n",
      "\n",
      "\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 655.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4335434436798096', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.504490852355957', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 657.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4335439205169678', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.5044920444488525', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 666.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.433544158935547', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.501446008682251', 'val_acc: 0.8359624743461609']\n",
      "\n",
      "\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 661.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4335429668426514', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.5044918060302734', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 662.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.433542013168335', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.507535934448242', 'val_acc: 0.8355631232261658']\n",
      "\n",
      "\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 663.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.433544874191284', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.5060136318206787', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 660.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4335432052612305', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.506014108657837', 'val_acc: 0.8356629610061646']\n",
      "\n",
      "\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 661.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4335427284240723', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.5044913291931152', 'val_acc: 0.8357627987861633']\n",
      "\n",
      "\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 640.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.433544874191284', 'acc: 0.840416669845581']\n",
      "['val_loss: 2.509059190750122', 'val_acc: 0.835463285446167']\n",
      "\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079aee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079aee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079aee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079a280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079a280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_1.<locals>.<lambda> at 0x7f4bc079a280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:03<00:00, 532.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4170260429382324', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4283664226531982', 'val_acc: 0.8407548069953918']\n",
      "\n",
      "\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 660.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.417025566101074', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4283666610717773', 'val_acc: 0.8407548069953918']\n",
      "\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 681.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.417022705078125', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.426845073699951', 'val_acc: 0.8408546447753906']\n",
      "\n",
      "\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 682.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4170241355895996', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.426845073699951', 'val_acc: 0.8408546447753906']\n",
      "\n",
      "\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 677.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4170243740081787', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4314119815826416', 'val_acc: 0.8405551314353943']\n",
      "\n",
      "\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 677.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.417025089263916', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4298901557922363', 'val_acc: 0.8406549692153931']\n",
      "\n",
      "\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 681.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4170234203338623', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4283676147460938', 'val_acc: 0.8407548069953918']\n",
      "\n",
      "\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 692.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.417025566101074', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.426844835281372', 'val_acc: 0.8408546447753906']\n",
      "\n",
      "\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 690.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.4170238971710205', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.428367853164673', 'val_acc: 0.8407548069953918']\n",
      "\n",
      "\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 678.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 2.417025566101074', 'acc: 0.8414999842643738']\n",
      "['val_loss: 2.4283676147460938', 'val_acc: 0.8407548069953918']\n",
      "\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc07878b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc07878b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc07878b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc0787a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc0787a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function prepare_subtask_2.<locals>.<lambda> at 0x7f4bc0787a60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                  | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ModelTwo.train_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e95b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ModelTwo.train_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e95b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method ModelTwo.train_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e95b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:03<00:00, 495.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.227718710899353', 'acc: 0.971014142036438']\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method ModelTwo.test_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e9220>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ModelTwo.test_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e9220>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method ModelTwo.test_step of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f4bc80e9220>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "['val_loss: 1.2142677307128906', 'val_acc: 0.9711845517158508']\n",
      "\n",
      "\n",
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 679.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2152365446090698', 'acc: 0.9710149765014648']\n",
      "['val_loss: 1.206214427947998', 'val_acc: 0.9711840748786926']\n",
      "\n",
      "\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 684.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.223254919052124', 'acc: 0.9710147976875305']\n",
      "['val_loss: 1.2061972618103027', 'val_acc: 0.971184492111206']\n",
      "\n",
      "\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 687.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2298868894577026', 'acc: 0.9710147976875305']\n",
      "['val_loss: 1.2471345663070679', 'val_acc: 0.971184253692627']\n",
      "\n",
      "\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 693.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2348397970199585', 'acc: 0.9710151553153992']\n",
      "['val_loss: 1.2262790203094482', 'val_acc: 0.971184253692627']\n",
      "\n",
      "\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 690.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2425817251205444', 'acc: 0.9710152745246887']\n",
      "['val_loss: 1.2158087491989136', 'val_acc: 0.9711843729019165']\n",
      "\n",
      "\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 688.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2499377727508545', 'acc: 0.9710152745246887']\n",
      "['val_loss: 1.203904390335083', 'val_acc: 0.9711848497390747']\n",
      "\n",
      "\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 686.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2574186325073242', 'acc: 0.9710149168968201']\n",
      "['val_loss: 1.2220274209976196', 'val_acc: 0.971184492111206']\n",
      "\n",
      "\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 682.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.2660272121429443', 'acc: 0.9709717631340027']\n",
      "['val_loss: 1.2538138628005981', 'val_acc: 0.9711847901344299']\n",
      "\n",
      "\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1875/1875 [00:02<00:00, 685.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss: 1.267561435699463', 'acc: 0.9709891676902771']\n",
      "['val_loss: 1.3715094327926636', 'val_acc: 0.9711838960647583']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run training with SGD and Adam\n",
    "# first subtask 1\n",
    "automated_training(1,tf.keras.optimizers.SGD(),10)\n",
    "automated_training(1,tf.keras.optimizers.Adam(),10)\n",
    "# subtask 2\n",
    "automated_training(1,tf.keras.optimizers.SGD(),10)\n",
    "automated_training(2,tf.keras.optimizers.Adam(),10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
