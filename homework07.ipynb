{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:42:40.883969: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 14:42:41.313625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/\n",
      "2022-12-13 14:42:41.313778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/\n",
      "2022-12-13 14:42:41.313783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:42:42.188677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.192281: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.192388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.192810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 14:42:42.193181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.193287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.193380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.454164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.454306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.454407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-13 14:42:42.454496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5250 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "(train_ds, test_ds), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='/home/hendrik/tensorflow_datasets/mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_target_fnc(ds, sequence_len):\n",
    "    \"\"\"\n",
    "    Creates list of new targets by alternately adding and subtracting\n",
    "    The first digit is added, the second subtracted, the third added, etc\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : TensorFlowDataset\n",
    "    original mnist dataset containg images and targets as a tuple.\n",
    "    sequence_len : int\n",
    "    indicates at which point the sum has to reset for the new sequence\n",
    "    Returns\n",
    "    -------\n",
    "    l : list\n",
    "    list containing the new targets\n",
    "    \"\"\"\n",
    "    l = list()\n",
    "    for i, elem in enumerate(ds):\n",
    "        if (i % sequence_len) == 0:\n",
    "            l.append(int(elem[1]))\n",
    "        else:\n",
    "            if (i % 2) == 0:\n",
    "                l.append(int(l[i-1] + elem[1]))\n",
    "            else:\n",
    "                l.append(int(l[i-1] - elem[1]))\n",
    "    return l\n",
    "\n",
    "\n",
    "# preprocess the data\n",
    "def preprocess(mnist, window_size):\n",
    "\n",
    "    # convert data from uint8 to float32\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # bringing image values from range [0,255] to [-1,1]\n",
    "    mnist = mnist.map(lambda img, target: ((img/128.)-1., target))\n",
    "    # generate new targets\n",
    "    new_targets = new_target_fnc(mnist,window_size)\n",
    "    # convert new targets into a dataset\n",
    "    new_targets = tf.data.Dataset.from_tensor_slices(new_targets)\n",
    "    # zip both datasets\n",
    "    mnist = tf.data.Dataset.zip((mnist, new_targets))\n",
    "    # replace old targets\n",
    "    mnist = mnist.map(lambda img, target: (img[0], target))\n",
    "    # generate multiple sequences\n",
    "    mnist = mnist.window(window_size, drop_remainder=True)\n",
    "    # cache progress in memory\n",
    "    mnist = mnist.cache()\n",
    "    # shuffle, batch, prefetch\n",
    "    mnist = mnist.shuffle(1000)\n",
    "    mnist = mnist.batch(32)\n",
    "    mnist = mnist.prefetch(20)\n",
    "    \n",
    "    # return processed dataset\n",
    "    return mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before zip\n",
      "<MapDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n",
      "after zip\n",
      "<ZipDataset element_spec=((TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None)), TensorSpec(shape=(), dtype=tf.int32, name=None))>\n",
      "<MapDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "#train_data = preprocess(train_ds, 10)\n",
    "test_data = preprocess(test_ds, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f15e42c1730>, <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f1573e0d070>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:50:48.645403: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "#visualize a sample of the dataset\n",
    "iterator = iter(train_data)\n",
    "print(iterator.get_next())\n",
    "#tf.shape(iterator.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "own implementation of a RNNCell\n",
    "takes the current data and the hidden / cell state of the previous cell as input\n",
    "'''\n",
    "class AbstractLayer(tf.keras.layers.AbstractRNNCell):\n",
    "    def __init__(self, unit_size):\n",
    "        super().__init__()\n",
    "              \n",
    "        # since there are three gates we need three Dense layers\n",
    "        # @TODO size should be the same as input, I guess\n",
    "        self.forget_gate = tf.keras.layers.Dense(unit_size, activation=\"sigmoid\")\n",
    "        self.input_gate = tf.keras.layers.Dense(unit_size, activation=\"sigmoid\")\n",
    "        self.candidate_gate = tf.keras.layers.Dense(unit_size, activation=\"tanh\")\n",
    "        self.output_gate = tf.keras.layers.Dense(unit_size, activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self, data, states):\n",
    "        \n",
    "        self.hidden_state = states[0]\n",
    "        self.cell_state = states[1]\n",
    "        # concatinate the hidden state and the new input together, to have in one list\n",
    "        concat_hidden_input = self.hidden_state.concat(data)\n",
    "        \n",
    "        # calculate the new cell state\n",
    "        forget_value = self.forget_gate(concat_hidden_input)\n",
    "        input_value = self.input_gate(concat_hidden_input)\n",
    "        candidate_value = self.candidate_gate(concat_hidden_input)\n",
    "        new_cell_state = forget_value * self.hidden_state + input_value * candidate_value\n",
    "        \n",
    "        # calculate the new hidden state\n",
    "        output_value = self.output_gate(concat_hidden_input)\n",
    "        new_hidden_state = output_value * tf.math.tanh(new_cell_state)\n",
    "        \n",
    "        # return the hidden state as an output of the current cell and a list containing the new states\n",
    "        return new_hidden_state, list(new_hidden_state, new_cell_state)\n",
    "    \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return [tf.TensorShape([self.forget_gate]),\n",
    "               tf.TensorShape([self.input_gate]),\n",
    "               tf.TensorShape([self.candidate_gate]),\n",
    "               tf.TensorShape([self.output_gate])]\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return [tf.TensorShape([self.output_gate])]\n",
    "    \n",
    "    def get_initial_state(inputs=None, batch_size=None, dtype=None):\n",
    "        return [tf.zeros([self.forget_gate]),\n",
    "               tf.zeros([self.input_gate]),\n",
    "               tf.zeros([self.candidate_gate]),\n",
    "               tf.zeros([self.output_gate])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #basic CNN structure to convert mnist matrix into a vector\n",
    "        input_shape = (32,10,28,28,1)\n",
    "        self.cnn_list = [tf.keras.layers.Conv2D(filters=24, kernel_size=3, padding='same', activation='relu', input_shape=input_shape[2:]),\n",
    "                        tf.keras.layers.Conv2D(filters=24, kernel_size=3, padding='same', activation='relu', input_shape=input_shape[2:]),\n",
    "                        tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAvgPool2D())]\n",
    "        \n",
    "        # get instance of our own implementation\n",
    "        self.lstm_cell = AbstractLayer(10)\n",
    "        # feed that instance into the wrapper class\n",
    "        self.rnn_layer = tf.keras.layers.RNN(self.lstm_cell, return_sequences=False, unroll=True)\n",
    "        # output layer\n",
    "        self.output_layer = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "        # metrics\n",
    "        self.metrics_list = [tf.keras.metrics.Mean(\"loss\"),\n",
    "                            tf.keras.metrics.CategoricalAccuracy()]\n",
    "       \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return self.metrics_list\n",
    "        \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_state()\n",
    "            \n",
    "    def call(self, sequence, training=False):\n",
    "        \n",
    "        # call CNN first\n",
    "        rnn_output = sequence\n",
    "        for layer in self.cnn_list:\n",
    "            rnn_output = layer(rnn_output)\n",
    "            \n",
    "        # call RNN second\n",
    "        rnn_output = self.rnn_layer(rnn_output)\n",
    "        \n",
    "        return self.output_layer(rnn_output)\n",
    "    \n",
    "    \n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Standard train_step method, assuming we use model.compile(optimizer, loss, ...)\n",
    "        \"\"\"\n",
    "        \n",
    "        sequence, label = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(sequence, training=True)\n",
    "            loss = self.compiled_loss(label, output, regularization_losses=self.losses)\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        \n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        self.metrics[0].update_state(loss)\n",
    "        self.metrics[1].update_state(label, output)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        \n",
    "        \"\"\"\n",
    "        Standard test_step method, assuming we use model.compile(optimizer, loss, ...)\n",
    "        \"\"\"\n",
    "        \n",
    "        sequence, label = data\n",
    "        output = self(sequence, training=False)\n",
    "        loss = self.compiled_loss(label, output, regularization_losses=self.losses)\n",
    "                \n",
    "        self.metrics[0].update_state(loss)\n",
    "        self.metrics[1].update_state(label, output)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# compile the model (here, adding a loss function and an optimizer)\n",
    "model.compile(optimizer = optimizer, loss=loss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"RNN_noise\"\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logging_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{EXPERIMENT_NAME}/{current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/tmp/ipykernel_16404/972140754.py\", line 49, in train_step\n        output = self(sequence, training=True)\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filez_0f93gv.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).cnn_list, None, loop_body, get_state, set_state, ('rnn_output',), {'iterate_names': 'layer'})\n    File \"/tmp/__autograph_generated_filez_0f93gv.py\", line 22, in loop_body\n        rnn_output = ag__.converted_call(ag__.ld(layer), (ag__.ld(rnn_output),), None, fscope)\n\n    TypeError: Exception encountered when calling layer 'rnn_model_6' (type RNNModel).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_16404/972140754.py\", line 34, in call  *\n            rnn_output = layer(rnn_output)\n        File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n            raise TypeError(f\"Inputs to a layer should be tensors. Got: {x}\")\n    \n        TypeError: Inputs to a layer should be tensors. Got: <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f15b443a130>\n    \n    \n    Call arguments received by layer 'rnn_model_6' (type RNNModel):\n      • sequence=<tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f15b443a130>\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlogging_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file2kv7e34v.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [47], line 49\u001b[0m, in \u001b[0;36mRNNModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     47\u001b[0m sequence, label \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 49\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(sequence, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     50\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(label, output, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[1;32m     51\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filez_0f93gv.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, sequence, training)\u001b[0m\n\u001b[1;32m     22\u001b[0m     rnn_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(layer), (ag__\u001b[38;5;241m.\u001b[39mld(rnn_output),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     23\u001b[0m layer \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m ag__\u001b[38;5;241m.\u001b[39mfor_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcnn_list, \u001b[38;5;28;01mNone\u001b[39;00m, loop_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrnn_output\u001b[39m\u001b[38;5;124m'\u001b[39m,), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterate_names\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     25\u001b[0m rnn_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrnn_layer, (ag__\u001b[38;5;241m.\u001b[39mld(rnn_output),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filez_0f93gv.py:22\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.loop_body\u001b[0;34m(itr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m rnn_output\n\u001b[1;32m     21\u001b[0m layer \u001b[38;5;241m=\u001b[39m itr\n\u001b[0;32m---> 22\u001b[0m rnn_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/tmp/ipykernel_16404/972140754.py\", line 49, in train_step\n        output = self(sequence, training=True)\n    File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filez_0f93gv.py\", line 24, in tf__call\n        ag__.for_stmt(ag__.ld(self).cnn_list, None, loop_body, get_state, set_state, ('rnn_output',), {'iterate_names': 'layer'})\n    File \"/tmp/__autograph_generated_filez_0f93gv.py\", line 22, in loop_body\n        rnn_output = ag__.converted_call(ag__.ld(layer), (ag__.ld(rnn_output),), None, fscope)\n\n    TypeError: Exception encountered when calling layer 'rnn_model_6' (type RNNModel).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_16404/972140754.py\", line 34, in call  *\n            rnn_output = layer(rnn_output)\n        File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/home/hendrik/anaconda3/envs/iannwtf-gpu/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 213, in assert_input_compatibility\n            raise TypeError(f\"Inputs to a layer should be tensors. Got: {x}\")\n    \n        TypeError: Inputs to a layer should be tensors. Got: <tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f15b443a130>\n    \n    \n    Call arguments received by layer 'rnn_model_6' (type RNNModel):\n      • sequence=<tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x7f15b443a130>\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    initial_epoch=25,\n",
    "                    epochs=50,\n",
    "                    callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend(labels=[\"training\",\"validation\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Binary Crossentropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with homework07\n",
    "\n",
    "Calling our Conv2D layers produced an error that we were not able to interpret correctly. We believe it to be due to our processing function. It might produce a wrong shape, but we were not able to figure out what was wrong with the shape, as we couldn't handle the _NestedVariant object that our function produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
