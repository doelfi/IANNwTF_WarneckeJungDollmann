{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1acce00",
   "metadata": {},
   "source": [
    "What this notebook does:\n",
    "\n",
    "- implement the normal mnist network from the homework </br>\n",
    "- testing and comparing different values for certain hyperparamters like \n",
    "    - number of units per hidden layer </br>\n",
    "    - number of hidden layers </br>\n",
    "    - momentum </br>\n",
    "    - step size </br>\n",
    "    - number of epochs </br>\n",
    "\n",
    "Each of these comparison has it's own cell that can be run independently.\n",
    "Click 'run all' on your own risk, it may take quite a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0a1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 12:12:11.480249: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-14 12:12:12.346856: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-14 12:12:12.347418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-14 12:12:12.366755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.366857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-11-14 12:12:12.366868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-14 12:12:12.367663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-14 12:12:12.367684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-14 12:12:12.368561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-14 12:12:12.368702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-14 12:12:12.369489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-14 12:12:12.369909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-14 12:12:12.371542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-14 12:12:12.371614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.371725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.371797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-14 12:12:12.372014: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-14 12:12:12.372417: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-14 12:12:12.372476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.372561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:07:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\n",
      "coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-11-14 12:12:12.372570: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-14 12:12:12.372580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-14 12:12:12.372586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-14 12:12:12.372591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-14 12:12:12.372596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-14 12:12:12.372600: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-14 12:12:12.372606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-14 12:12:12.372611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-14 12:12:12.372642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.372735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:12.372803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-14 12:12:12.372818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-14 12:12:13.045993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-14 12:12:13.046011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-11-14 12:12:13.046015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-11-14 12:12:13.046166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:13.046287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:13.046389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-14 12:12:13.046492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "(train_ds, test_ds), ds_info = tfds.load('mnist', split=['train', 'test'], as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f701a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_path='/home/hendrik/tensorflow_datasets/mnist/3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bd1a5",
   "metadata": {},
   "source": [
    "How many training/test images are there? </br>\n",
    "training: 60000 </br>\n",
    "test: 10000\n",
    "\n",
    "What's the image shape? </br>\n",
    "28 * 28 \n",
    "\n",
    "What range are pixel values in? </br>\n",
    "8 bit -> 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe90d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 12:12:13.355019: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-14 12:12:13.355250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3792895000 Hz\n",
      "2022-11-14 12:12:13.366860: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.show_examples(train_ds, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256c0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the data pipeline\n",
    "\n",
    "def prepare_mnist_data(mnist):\n",
    "    # flatten the images into vectors\n",
    "    mnist = mnist.map(lambda img, target: (tf.reshape(img, (-1,)), target))\n",
    "    # convert data from uint8 to float32\n",
    "    mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
    "    # bringing image values from range [0,255] to [-1,1]\n",
    "    mnist = mnist.map(lambda img, target: ((img/128.)-1., target))\n",
    "    # create one-hot targets\n",
    "    mnist = mnist.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
    "    # cache progress in memory\n",
    "    mnist = mnist.cache()\n",
    "    # shuffle, batch, prefetch\n",
    "    mnist = mnist.shuffle(1000)\n",
    "    mnist = mnist.batch(32)\n",
    "    mnist = mnist.prefetch(20)\n",
    "    # return processed dataset\n",
    "    return mnist\n",
    "\n",
    "train_dataset = train_ds.apply(prepare_mnist_data)\n",
    "test_dataset = test_ds.apply(prepare_mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdd2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    # two hidden layers + output layer\n",
    "    def __init__(self, n_units):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(n_units, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(n_units, activation=tf.nn.relu)\n",
    "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    \n",
    "    # propagate the input through all layers until the output\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131f1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training and test functions\n",
    "import numpy as np\n",
    "\n",
    "# backpropagation using the GradientTape to get the gradients and then apply them via the optimizer\n",
    "def train_step(model, input, target, loss_function, optimizer):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = model(input)\n",
    "        loss = loss_function(target, prediction)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# to test with an independent data set, storing some metrics for every step\n",
    "def test(model, test_data, loss_function):\n",
    "    \n",
    "    test_accuracy_aggregator = []\n",
    "    test_loss_aggregator = []\n",
    "    \n",
    "    for (input, target) in test_data:\n",
    "        prediction = model(input)\n",
    "        sample_test_loss = loss_function(target, prediction)\n",
    "        sample_test_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
    "        sample_test_accuracy = np.mean(sample_test_accuracy)\n",
    "        test_loss_aggregator.append(sample_test_loss.numpy())\n",
    "        test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
    "        \n",
    "    test_loss = tf.reduce_mean(test_loss_aggregator)\n",
    "    test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd8674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used the example from the homework sheet but removed the train accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "def visualization (train_losses, test_losses, test_accuracies):\n",
    "    \"\"\" Visualizes accuracy and loss for training and test data using\n",
    "    the mean of each epoch .\n",
    "    Loss is displayed in a regular line , accuracy in a dotted\n",
    "    line .\n",
    "    Training data is displayed in blue , test data in red .\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_losses : numpy.ndarray\n",
    "    training losses\n",
    "    training accuracies\n",
    "    test_losses : numpy.ndarray\n",
    "    test losses\n",
    "    test_accuracies : numpy.ndarray\n",
    "    test accuracies\n",
    "    \"\"\"\n",
    "    print(\"train losses: \")\n",
    "    print(train_losses)\n",
    "    print(\"test losses: \")\n",
    "    print(test_losses)\n",
    "    print(\"test accuracies: \")\n",
    "    print(test_accuracies)\n",
    "    \n",
    "    plt.figure()\n",
    "    line1, = plt.plot(train_losses, \"b-\")\n",
    "    line2, = plt.plot(test_losses, \"r-\")\n",
    "    line4, = plt.plot(test_accuracies, \"r:\")\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend((line1, line2, line4), (\"training loss\", \"test loss\", \"test accuracy\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the normal configuration from task 2\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize the model\n",
    "model = MyModel(256)\n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "# Initialize the optimizer: SGD with default parameters.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Initialize lists for later visualization\n",
    "train_losses = []\n",
    "#train_accuracies\n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# testing once before we begin\n",
    "#test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "#test_losses.append(test_loss)\n",
    "#test_accuracies.append(test_accuracy)\n",
    "\n",
    "# check how model performs on train data once before we begin\n",
    "train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "train_losses.append(train_loss)\n",
    "#train_accuracies.append(train_accuracy)\n",
    "\n",
    "# we train for num_epochs epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_agg = []\n",
    "    for input,target in train_dataset:\n",
    "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "        epoch_loss_agg.append(train_loss)\n",
    "        \n",
    "    # track training loss\n",
    "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "    \n",
    "    # testing, so we can track accuracy and test loss\n",
    "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "visualization(train_losses, test_losses, test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8ab5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer size: 24\n",
      "test accuracy: tf.Tensor(0.9491813099041534, shape=(), dtype=float64)\n",
      "layer size: 23\n",
      "test accuracy: tf.Tensor(0.9517771565495208, shape=(), dtype=float64)\n",
      "layer size: 22\n",
      "test accuracy: tf.Tensor(0.9464856230031949, shape=(), dtype=float64)\n",
      "layer size: 21\n",
      "test accuracy: tf.Tensor(0.9497803514376997, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### run with different number of units per layer ###\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize the models\n",
    "# create one model per entry in layer_sizes\n",
    "layer_sizes = [24,23,22,21]\n",
    "models = []\n",
    "for i in range(len(layer_sizes)):\n",
    "    model = MyModel(layer_sizes[i])\n",
    "    models.append(model)\n",
    "    \n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Initialize the optimizer: SGD with default parameters.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "n = 0\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    # Initialize lists for later visualization\n",
    "    train_losses = []\n",
    "    #train_accuracies\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    #train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # we train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        # track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        # testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    # printing the results (mostly interested in the accuracy of the test dataset)\n",
    "    print(\"layer size: \" + str(layer_sizes[n]))\n",
    "    print(\"test accuracy: \" + str(test_accuracies[-1]))\n",
    "    n = n + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbdfdf5",
   "metadata": {},
   "source": [
    "Some results from running the above with different values:\n",
    "\n",
    "layer size: 256 accuracy: 0.9739 </br>\n",
    "layer size: 200 accuracy: 0.9697 </br>\n",
    "layer size: 100 accuracy: 0.9667 </br>\n",
    "layer size: 50 accuracy: 0.9634 </br>\n",
    "layer size: 25 accuracy: 0.9531 </br>\n",
    "layer size: 24 accuracy: 0.9491 </br>\n",
    "layer size: 23 accuracy: 0.9517 </br>\n",
    "layer size: 22 accuracy: 0.9464 </br>\n",
    "layer size: 21 accuracy: 0.9667 </br>\n",
    "layer size: 20 accuracy: 0.9460 </br>\n",
    "\n",
    "-> probably reduceable to 20 with changing other parameters (when taking >95% as a threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac021a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 0.04\n",
      "test accuracy: tf.Tensor(0.9475838658146964, shape=(), dtype=float64)\n",
      "step size: 0.02\n",
      "test accuracy: tf.Tensor(0.9602635782747604, shape=(), dtype=float64)\n",
      "step size: 0.01\n",
      "test accuracy: tf.Tensor(0.959464856230032, shape=(), dtype=float64)\n",
      "step size: 0.005\n",
      "test accuracy: tf.Tensor(0.9601637380191693, shape=(), dtype=float64)\n",
      "step size: 0.001\n",
      "test accuracy: tf.Tensor(0.9615615015974441, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### run same layersize with different learning rates\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rates = [0.04, 0.02, 0.01, 0.005, 0.001]\n",
    "\n",
    "# Initialize the models\n",
    "# since I tried to get a layersize of 20 to over 95% accuracy I just rolled with that from here\n",
    "# this time we also need a different optimizer object for every model\n",
    "layer_size = 20\n",
    "models = []\n",
    "optimizers = []\n",
    "for i in range(len(learning_rates)):\n",
    "    model = MyModel(layer_size)\n",
    "    models.append(model)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rates[i])\n",
    "    optimizers.append(optimizer)\n",
    "    \n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "\n",
    "\n",
    "for n in range(len(models)):\n",
    "    \n",
    "    # Initialize lists for later visualization\n",
    "    train_losses = []\n",
    "    #train_accuracies\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    #train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # we train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizers[n])\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        # track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        # testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    # print accuracy\n",
    "    print(\"step size: \" + str(learning_rates[n]))\n",
    "    print(\"test accuracy: \" + str(test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f0529",
   "metadata": {},
   "source": [
    "Some results from running the above with different values:\n",
    "\n",
    "step size: 0.04 acccuracy: 0.9527 </br>\n",
    "step size: 0.02 accuracy: 0.9580 </br>\n",
    "step size: 0.01 accuracy: 0.9586 </br>\n",
    "step size: 0.005 accuracy: 0.9586 </br>\n",
    "step size: 0.001 accuracy: 0.9608 </br>\n",
    "\n",
    "-> reducing step size gave a slight advantage in this case (n_units = 20)\n",
    "But they can underly variance! (next run the accuracy might be closer to 0.90 or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f674c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step size: 0.9\n",
      "test accuracy: tf.Tensor(0.9438897763578274, shape=(), dtype=float64)\n",
      "step size: 1\n",
      "test accuracy: tf.Tensor(0.0961461661341853, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### different momentum values\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "# using the learning rate with the best results from the last test\n",
    "learning_rate = 0.001\n",
    "momentum_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "\n",
    "# Initialize the models\n",
    "# again we need multiple optimizers with different paramters\n",
    "layer_size = 20\n",
    "models = []\n",
    "optimizers = []\n",
    "for i in range(len(momentum_values)):\n",
    "    model = MyModel(layer_size)\n",
    "    models.append(model)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate, momentum=momentum_values[i])\n",
    "    optimizers.append(optimizer)\n",
    "    \n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Initialize the optimizer: SGD with default parameters.\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "\n",
    "for n in range(len(models)):\n",
    "    \n",
    "    # Initialize lists for later visualization\n",
    "    train_losses = []\n",
    "    #train_accuracies\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    #train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # we train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizers[n])\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        # track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        # testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    # print accuracy\n",
    "    print(\"momentum: \" + str(momentum_values[n]))\n",
    "    print(\"test accuracy: \" + str(test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c5fdb",
   "metadata": {},
   "source": [
    "Some previous results from running the above:\n",
    "\n",
    "momentum: 0 accuracy: 0.9020 </br>\n",
    "momentum: 0.2 accuracy: 0.9228 </br>\n",
    "momentum: 0.4 accuracy: 0.9331 </br>\n",
    "momentum: 0.6 accuracy: 0.9410 </br>\n",
    "momentum: 0.8 accuracy: 0.9510 </br>\n",
    "momentum: 0.9 accuracy: 0.9439 </br>\n",
    "momentum: 1 accuracy: 0.0096 </br>\n",
    "\n",
    "-> accuracy increased with momentum (as long as momentum < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d38d6bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs size: 10\n",
      "test accuracy: tf.Tensor(0.9341054313099042, shape=(), dtype=float64)\n",
      "epochs size: 15\n",
      "test accuracy: tf.Tensor(0.952276357827476, shape=(), dtype=float64)\n",
      "epochs size: 20\n",
      "test accuracy: tf.Tensor(0.9564696485623003, shape=(), dtype=float64)\n",
      "epochs size: 25\n",
      "test accuracy: tf.Tensor(0.9582667731629393, shape=(), dtype=float64)\n",
      "epochs size: 30\n",
      "test accuracy: tf.Tensor(0.9562699680511182, shape=(), dtype=float64)\n",
      "epochs size: 50\n",
      "test accuracy: tf.Tensor(0.957867412140575, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### different number of epochs\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = [10, 15, 20, 25, 30, 50]\n",
    "learning_rate = 0.001\n",
    "# again, using the best result from above to continue with testing\n",
    "momentum_value = 0.8\n",
    "\n",
    "# Initialize the models\n",
    "layer_size = 20\n",
    "models = []\n",
    "optimizers = []\n",
    "for i in range(len(num_epochs)):\n",
    "    model = MyModel(layer_size)\n",
    "    models.append(model)    \n",
    "    \n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Initialize the optimizer: SGD with default parameters.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate, momentum=0.8)\n",
    "\n",
    "#train every model\n",
    "for n in range(len(models)):\n",
    "    \n",
    "    # Initialize lists for later visualization\n",
    "    train_losses = []\n",
    "    #train_accuracies\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    #train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # we train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs[n]):\n",
    "        epoch_loss_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        # track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        # testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    #print accuracies\n",
    "    print(\"epochs size: \" + str(num_epochs[n]))\n",
    "    print(\"test accuracy: \" + str(test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d91f72",
   "metadata": {},
   "source": [
    "epochs: 10 accuracy: 0.9341 </br>\n",
    "epochs: 15 accuracy: 0.9523 </br>\n",
    "epochs: 20 accuracy: 0.9564 </br>\n",
    "epochs: 25 accuracy: 0.9583 </br>\n",
    "epochs: 30 accuracy: 0.9563 </br>\n",
    "epochs: 50 accuracy: 0.9579 </br>\n",
    "\n",
    "-> only slight benefit of higher epochs but adding a lot of additional computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c9f120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 1\n",
      "test accuracy: tf.Tensor(0.9482827476038339, shape=(), dtype=float64)\n",
      "layers: 2\n",
      "test accuracy: tf.Tensor(0.9555710862619808, shape=(), dtype=float64)\n",
      "layers: 3\n",
      "test accuracy: tf.Tensor(0.9549720447284346, shape=(), dtype=float64)\n",
      "layers: 4\n",
      "test accuracy: tf.Tensor(0.954173322683706, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "### different number of layers\n",
    "\n",
    "# Version of the MyModel where the number of layers is variable\n",
    "# but every hidden layer will get the same number of units\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class MyModel2(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, n_layers, n_units):\n",
    "        super(MyModel2, self).__init__()\n",
    "        self.denseL = []\n",
    "        for i in range(n_layers):\n",
    "            self.denseL.append(tf.keras.layers.Dense(n_units, activation=tf.nn.relu))\n",
    "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.denseL:\n",
    "            x = layer(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyperparameters\n",
    "# as more epochs only marginaly increased performance I decided on 20 epochs, to keep computational effort lower\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "momentum_value = 0.8\n",
    "\n",
    "# Initialize the models\n",
    "layer_size = 20\n",
    "num_layers = [1,2,3,4]\n",
    "models = []\n",
    "optimizers = []\n",
    "for i in range(len(num_layers)):\n",
    "    model = MyModel2(num_layers[i],layer_size)\n",
    "    models.append(model)    \n",
    "    \n",
    "# Initialize the loss: categorial cross entropy.\n",
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Initialize the optimizer: SGD with default parameters.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate, momentum=0.8)\n",
    "\n",
    "\n",
    "for n in range(len(models)):\n",
    "    \n",
    "    # Initialize lists for later visualization\n",
    "    train_losses = []\n",
    "    #train_accuracies\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # testing once before we begin\n",
    "    test_loss, test_accuracy = test(model,test_dataset, cross_entropy_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    #test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # check how model performs on train data once before we begin\n",
    "    train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    #train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # we train for num_epochs epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_agg = []\n",
    "        for input,target in train_dataset:\n",
    "            train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
    "            epoch_loss_agg.append(train_loss)\n",
    "\n",
    "        # track training loss\n",
    "        train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
    "\n",
    "        # testing, so we can track accuracy and test loss\n",
    "        test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "    # get accuracy\n",
    "    print(\"layers: \" + str(num_layers[n]))\n",
    "    print(\"test accuracy: \" + str(test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54306435",
   "metadata": {},
   "source": [
    "Some results from testing the above:\n",
    "\n",
    "layers: 1 accuracy: 0.9483 </br>\n",
    "layers: 2 accuracy: 0.9556 </br>\n",
    "layers: 3 accuracy: 0.9550 </br>\n",
    "layers: 4 accuracy: 0.9542 </br>\n",
    "\n",
    "-> additional layers do not seem to increase performance in this case, even one layer already performed quite well. It could be that more layers require more training steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:iannwtf-gpu]",
   "language": "python",
   "name": "conda-env-iannwtf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
